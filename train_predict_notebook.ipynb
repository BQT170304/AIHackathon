{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7345809,"sourceType":"datasetVersion","datasetId":4265524},{"sourceId":7368142,"sourceType":"datasetVersion","datasetId":4280626},{"sourceId":7436232,"sourceType":"datasetVersion","datasetId":4327842},{"sourceId":7436855,"sourceType":"datasetVersion","datasetId":4328296},{"sourceId":7438837,"sourceType":"datasetVersion","datasetId":4329510},{"sourceId":7438840,"sourceType":"datasetVersion","datasetId":4329511},{"sourceId":7438851,"sourceType":"datasetVersion","datasetId":4329519}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ast\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision\nfrom torchvision import models, transforms","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:37.912606Z","iopub.execute_input":"2024-01-20T03:53:37.913584Z","iopub.status.idle":"2024-01-20T03:53:39.905648Z","shell.execute_reply.started":"2024-01-20T03:53:37.913547Z","shell.execute_reply":"2024-01-20T03:53:39.904725Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATADIR = '/kaggle/input/ai-challenge/data/mnt/md0/projects/sami-hackathon/private/data/'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu' \nimage_size = 224\ntrain_transform = transforms.Compose([transforms.Resize((image_size, image_size)),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                           std = [0.225, 0.225, 0.225])])\nval_transform = transforms.Compose([transforms.Resize((image_size, image_size)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                         std = [0.225, 0.225, 0.225])])\n\ndf = pd.read_csv('/kaggle/input/ai-challenge/labels.csv')\ndf[df.file_name == 'image_4503.jpg']","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:40.710926Z","iopub.execute_input":"2024-01-20T03:53:40.712006Z","iopub.status.idle":"2024-01-20T03:53:40.829834Z","shell.execute_reply.started":"2024-01-20T03:53:40.711972Z","shell.execute_reply":"2024-01-20T03:53:40.828855Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"            file_name  height  width  \\\n14777  image_4503.jpg    1024   1024   \n\n                                                    bbox   age       race  \\\n14777  [261.2020202020202, 147.9292929292934, 618.696...  Baby  Mongoloid   \n\n         masked skintone  emotion  gender  \n14777  unmasked    light  Neutral  Female  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>height</th>\n      <th>width</th>\n      <th>bbox</th>\n      <th>age</th>\n      <th>race</th>\n      <th>masked</th>\n      <th>skintone</th>\n      <th>emotion</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14777</th>\n      <td>image_4503.jpg</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>[261.2020202020202, 147.9292929292934, 618.696...</td>\n      <td>Baby</td>\n      <td>Mongoloid</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Neutral</td>\n      <td>Female</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"image_paths = [DATADIR + path for path in list(df.file_name)]\nbbox = [[float(i.strip()) for i in box.replace(\"[\", \"\").replace(\"]\", \"\").split(',')] for box in df.bbox]\nage = list(df.age)\nrace = list(df.race)\nmasked = [1 if i == 'masked' else 0 for i in list(df.masked)]\nskin = list(df.skintone)\nemotion = list(df.emotion)\ngender = list(df.gender)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:43.017509Z","iopub.execute_input":"2024-01-20T03:53:43.018304Z","iopub.status.idle":"2024-01-20T03:53:43.100192Z","shell.execute_reply.started":"2024-01-20T03:53:43.018269Z","shell.execute_reply":"2024-01-20T03:53:43.099220Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def convert2dict(li):\n    values, counts = np.unique(li, return_counts=True)\n    result_dict = {value: count for value, count in zip(values, counts)}\n    return result_dict\n\ndef plot_valcount(di, name):\n    keys = list(di.keys())\n    values = list(di.values())\n\n    # Plot the figure\n    fig, ax = plt.subplots()\n    ax.bar(keys, values)\n    ax.set_title(name)\n\n    plt.show()\n\n\ndata_dict = {\n    'Age': convert2dict(age),\n    'Race': convert2dict(race),\n    'Masked': convert2dict(masked),\n    'Skin': convert2dict(skin),\n    'Emotion': convert2dict(emotion),\n    'Gender': convert2dict(gender),\n}\n\ndata_dict","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:49.480453Z","iopub.execute_input":"2024-01-20T03:53:49.480920Z","iopub.status.idle":"2024-01-20T03:53:49.524861Z","shell.execute_reply.started":"2024-01-20T03:53:49.480879Z","shell.execute_reply":"2024-01-20T03:53:49.523980Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'Age': {'20-30s': 11236,\n  '40-50s': 1602,\n  'Baby': 345,\n  'Kid': 954,\n  'Senior': 637,\n  'Teenager': 536},\n 'Race': {'Caucasian': 7106, 'Mongoloid': 7487, 'Negroid': 717},\n 'Masked': {0: 14806, 1: 504},\n 'Skin': {'dark': 339, 'light': 10485, 'mid-dark': 798, 'mid-light': 3688},\n 'Emotion': {'Anger': 319,\n  'Disgust': 132,\n  'Fear': 114,\n  'Happiness': 9218,\n  'Neutral': 4844,\n  'Sadness': 380,\n  'Surprise': 303},\n 'Gender': {'Female': 10522, 'Male': 4788}}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataframe for skin data","metadata":{}},{"cell_type":"code","source":"dark_df = pd.concat([df[df.skintone == 'dark']]*4)\nmiddark_df = pd.concat([df[df.skintone == 'mid-dark']]*2)\nmidlight_df = df[df.skintone == 'mid-light']\nlight_df = df[df.skintone == 'light']\nlen(dark_df), len(light_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"young_df = df[df.age == '20-30s']\nold_df = df[df.age == '40-50s']\nbaby_df = pd.concat([df[df.age == 'Baby']]*5)\nkid_df = pd.concat([df[df.age == 'Kid']]*2)\nsenior_df= pd.concat([df[df.age == 'Senior']]*3)\nteen_df = pd.concat([df[df.age == 'Teenager']]*4)\nyoung_df.shape[0], old_df.shape[0], baby_df.shape[0], kid_df.shape[0], senior_df.shape[0],teen_df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:56.121999Z","iopub.execute_input":"2024-01-20T03:53:56.122995Z","iopub.status.idle":"2024-01-20T03:53:56.161555Z","shell.execute_reply.started":"2024-01-20T03:53:56.122959Z","shell.execute_reply":"2024-01-20T03:53:56.160528Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(11236, 1602, 1725, 1908, 1911, 2144)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Get face with bounding box","metadata":{}},{"cell_type":"code","source":"from math import ceil\ndef get_coordinate(box):\n    x1 = box[0]\n    y1 = box[1]\n    x2 = box[0] + box[2]\n    y2 = box[1] + box[3]\n    return (x1,y1,x2,y2)\n\ndef get_crop_face(img, box):\n    x1,y1,x2,y2 = get_coordinate(box)\n    x1,y1,x2,y2 = ceil(x1), ceil(y1), ceil(x2), ceil(y2)\n    return img[y1:y2, x1:x2, :]","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:57.810704Z","iopub.execute_input":"2024-01-20T03:53:57.811412Z","iopub.status.idle":"2024-01-20T03:53:57.818108Z","shell.execute_reply.started":"2024-01-20T03:53:57.811375Z","shell.execute_reply":"2024-01-20T03:53:57.817073Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess data","metadata":{}},{"cell_type":"code","source":"def shuffle_with_permutation(lst, permutation):\n        combined = sorted(zip(lst, permutation), key=lambda x: x[1])\n        shuffled_list = [item[0] for item in combined]\n        return shuffled_list","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:53:59.827803Z","iopub.execute_input":"2024-01-20T03:53:59.828534Z","iopub.status.idle":"2024-01-20T03:53:59.833520Z","shell.execute_reply.started":"2024-01-20T03:53:59.828497Z","shell.execute_reply":"2024-01-20T03:53:59.832559Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Masked data","metadata":{}},{"cell_type":"code","source":"class MaskedDataset(Dataset):\n    def __init__(self, transform):\n        super().__init__()\n        unmasked_list, masked_list = [], []\n        idx = []\n    \n        for i in range(len(masked)):\n            if masked[i] == 1:\n                masked_list.append(masked[i])\n                idx.append(i)\n        \n        random_idx = np.random.choice(range(len(masked)), size=len(idx)*2, replace=False)\n        idx.extend(list(random_idx))\n        idx = random.sample(idx, len(idx))\n        self.image_paths = [image_paths[i] for i in idx]\n        self.bbox = [bbox[i] for i in idx]\n        self.label = [masked[i] for i in idx]\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.label)\n\n    def __getitem__(self, index):\n        path = self.image_paths[index]\n        image = np.array(Image.open(path))\n        box = self.bbox[index]\n        crop_img = get_crop_face(image, box)\n        face = Image.fromarray(crop_img)\n        print(path)\n        label = self.label[index]\n        if label == 1:\n            face = self.transform(face)\n        else:\n            face = val_transform(face)\n        return face, label\n    \nmasked_data = MaskedDataset(train_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RaceSkin data","metadata":{}},{"cell_type":"code","source":"def process_race_label(label):\n    if (label=='Caucasian'):\n        return 0\n    elif (label=='Mongoloid'):\n        return 1\n    else:\n        return 2\ndef process_skin_label(label):\n    if (label=='dark'):\n        return 0\n    elif (label=='mid-dark'):\n        return 1\n    elif (label=='light'):\n        return 2\n    else:\n        return 3\n\nclass RaceSkinDataset(Dataset):\n    def __init__(self, transform):\n        super().__init__()\n        image_paths, bbox = [], []\n        skin, race = [], []\n        \n        for i in range(dark_df.shape[0]):\n            image_paths.append(DATADIR + dark_df.iloc[i]['file_name'])\n            bbox.append(dark_df.iloc[i]['bbox'])\n            skin.append(process_skin_label(dark_df.iloc[i]['skintone']))\n            race.append(process_race_label(dark_df.iloc[i]['race']))\n\n        for i in range(middark_df.shape[0]):\n            image_paths.append(DATADIR + middark_df.iloc[i]['file_name'])\n            bbox.append(middark_df.iloc[i]['bbox'])\n            skin.append(process_skin_label(middark_df.iloc[i]['skintone']))\n            race.append(process_race_label(middark_df.iloc[i]['race']))\n\n        exclude = []\n        for i in range(middark_df.shape[0]):\n            id = random.randint(0, midlight_df.shape[0] - 1)\n            while id in exclude:\n                id = random.randint(0, midlight_df.shape[0] - 1)\n            exclude.append(id)\n            image_paths.append(DATADIR + midlight_df.iloc[id]['file_name'])\n            bbox.append(midlight_df.iloc[id]['bbox'])\n            skin.append(process_skin_label(midlight_df.iloc[id]['skintone']))\n            race.append(process_race_label(midlight_df.iloc[id]['race']))\n\n        exclude = []\n        for i in range(middark_df.shape[0]):\n            id = random.randint(0, light_df.shape[0] - 1)\n            while id in exclude:\n                id = random.randint(0, light_df.shape[0] - 1)\n            exclude.append(id)\n            image_paths.append(DATADIR + light_df.iloc[id]['file_name'])\n            bbox.append(light_df.iloc[id]['bbox'])\n            skin.append(process_skin_label(light_df.iloc[id]['skintone']))\n            race.append(process_race_label(light_df.iloc[id]['race']))\n        \n        idx = [i for i in range(len(image_paths))]\n        random.shuffle(idx)\n        self.image_paths = shuffle_with_permutation(image_paths, idx)\n        self.bbox = shuffle_with_permutation(bbox, idx)\n        self.skin = shuffle_with_permutation(skin, idx)\n        self.race = shuffle_with_permutation(race, idx)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        path = self.image_paths[index]\n        image = np.array(Image.open(path))\n        box = self.bbox[index]\n        box = [float(i.strip()) for i in box.replace(\"[\", \"\").replace(\"]\", \"\").split(',')]\n        crop_img = get_crop_face(image, box)\n        face = Image.fromarray(crop_img)\n        race = self.race[index]\n        skin = self.skin[index]\n        face = self.transform(face)\n        return face, race, skin\n    \nraceskin_data = RaceSkinDataset(train_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face, mask = masked_data[156]\nmask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Age data","metadata":{}},{"cell_type":"code","source":"def process_age_label(label):\n    if (label=='20-30s'):\n        return 0\n    elif (label=='40-50s'):\n        return 1\n    elif (label=='Baby'):\n        return 2\n    elif (label=='Kid'):\n        return 3\n    elif (label=='Senior'):\n        return 4\n    else:\n        return 5\n\nclass AgeDataset(Dataset):\n    def __init__(self, transform):\n        super().__init__()\n        image_paths, bbox, age = [], [], []\n        \n        for i in range(teen_df.shape[0]):\n            image_paths.append(DATADIR + teen_df.iloc[i]['file_name'])\n            bbox.append(teen_df.iloc[i]['bbox'])\n            age.append(process_age_label(teen_df.iloc[i]['age']))\n\n        for i in range(old_df.shape[0]):\n            image_paths.append(DATADIR + old_df.iloc[i]['file_name'])\n            bbox.append(old_df.iloc[i]['bbox'])\n            age.append(process_age_label(old_df.iloc[i]['age']))\n            \n        for i in range(baby_df.shape[0]):\n            image_paths.append(DATADIR + baby_df.iloc[i]['file_name'])\n            bbox.append(baby_df.iloc[i]['bbox'])\n            age.append(process_age_label(baby_df.iloc[i]['age']))\n            \n        for i in range(kid_df.shape[0]):\n            image_paths.append(DATADIR + kid_df.iloc[i]['file_name'])\n            bbox.append(kid_df.iloc[i]['bbox'])\n            age.append(process_age_label(kid_df.iloc[i]['age']))\n            \n        for i in range(senior_df.shape[0]):\n            image_paths.append(DATADIR + senior_df.iloc[i]['file_name'])\n            bbox.append(senior_df.iloc[i]['bbox'])\n            age.append(process_age_label(senior_df.iloc[i]['age']))\n            \n        exclude = []\n        for i in range(teen_df.shape[0]):\n            id = random.randint(0, teen_df.shape[0] - 1)\n            while id in exclude:\n                id = random.randint(0, teen_df.shape[0] - 1)\n            exclude.append(id)\n            image_paths.append(DATADIR + teen_df.iloc[id]['file_name'])\n            bbox.append(teen_df.iloc[id]['bbox'])\n            age.append(process_age_label(teen_df.iloc[id]['age']))\n        \n        idx = [i for i in range(len(image_paths))]\n        random.shuffle(idx)\n        self.image_paths = shuffle_with_permutation(image_paths, idx)\n        self.bbox = shuffle_with_permutation(bbox, idx)\n        self.age = shuffle_with_permutation(age, idx)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        path = self.image_paths[index]\n        image = np.array(Image.open(path))\n        box = self.bbox[index]\n        box = [float(i.strip()) for i in box.replace(\"[\", \"\").replace(\"]\", \"\").split(',')]\n        crop_img = get_crop_face(image, box)\n        face = Image.fromarray(crop_img)\n        age = self.age[index]\n        face = self.transform(face)\n        return face, age\n\nage_data = AgeDataset(train_transform)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:54:03.071717Z","iopub.execute_input":"2024-01-20T03:54:03.072565Z","iopub.status.idle":"2024-01-20T03:54:05.491253Z","shell.execute_reply.started":"2024-01-20T03:54:03.072533Z","shell.execute_reply":"2024-01-20T03:54:05.490384Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"face1, age = age_data[59]\nface1, age","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- (classifier): Sequential(\n    - (0): Linear(in_features=25088, out_features=4096, bias=True)\n    - (1): ReLU(inplace=True)\n    - (2): Dropout(p=0.5, inplace=False)\n    - (3): Linear(in_features=4096, out_features=4096, bias=True)\n    - (4): ReLU(inplace=True)\n    - (5): Dropout(p=0.5, inplace=False)\n    - (6): Linear(in_features=4096, out_features=1000, bias=True)\n- )","metadata":{}},{"cell_type":"code","source":"class AgeModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = torch.load('/kaggle/working/backbone.pt')\n        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n                                  nn.Flatten())\n        self.fc = nn.Sequential(nn.Linear(in_features=25088, out_features=4096, bias=True),\n                                nn.ReLU(inplace=True),\n                                nn.Dropout())\n        self.fc.load_state_dict(torch.load('/kaggle/working/fc.pth'))\n        self.agecls = nn.Linear(in_features=4096, out_features=6, bias=False)\n        self.agecls.load_state_dict(torch.load('/kaggle/working/age.pth'))\n        \n    def forward(self, x):\n        out = self.pool(self.backbone(x))\n        return self.agecls(self.fc(out))\n\namodel = AgeModel().to(device)\nfor p in amodel.backbone.parameters():\n    p.requires_grad = False\nfor p in amodel.fc.parameters():\n    p.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:54:30.026419Z","iopub.execute_input":"2024-01-20T03:54:30.026835Z","iopub.status.idle":"2024-01-20T03:54:31.429999Z","shell.execute_reply.started":"2024-01-20T03:54:30.026803Z","shell.execute_reply":"2024-01-20T03:54:31.429088Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Masked model","metadata":{}},{"cell_type":"code","source":"class TestModel(nn.Module):\n    def __init__(self, nrace=3, nskin=4):\n        super().__init__()\n        self.backbone = torch.load('/kaggle/working/backbone.pt', map_location=torch.device('cpu'))\n        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n                                  nn.Flatten())\n        self.fc = nn.Sequential(nn.Linear(in_features=25088, out_features=4096, bias=True),\n                                nn.ReLU(inplace=True),\n                                nn.Dropout())\n        self.fc.load_state_dict(torch.load('/kaggle/working/fc.pth', map_location=torch.device('cpu')))\n        \n        self.racecls = nn.Linear(in_features=4096, out_features=nrace, bias=False)\n        self.racecls.load_state_dict(torch.load('/kaggle/working/race.pth', map_location=torch.device('cpu')))\n        self.skincls = nn.Linear(in_features=4096, out_features=nskin, bias=False) \n        self.skincls.load_state_dict(torch.load('/kaggle/working/skin.pth', map_location=torch.device('cpu')))\n        \n#         self.fc = torch.load('/kaggle/working/fc.pt')\n#         self.pool = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n#                                   nn.Flatten())\n#         self.racecls = torch.load('/kaggle/working/race.pt')\n#         self.skincls = torch.load('/kaggle/working/skin.pt')\n    \n    def forward(self, x):\n        out = self.pool(self.backbone(x))\n        return self.racecls(self.fc(out)), self.skincls(self.fc(out))\n\n    \n# tmodel = TestModel().to(device)\ntmodel2 = TestModel().to(device)\n# for param in tmodel.backbone.parameters():\n#     param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main model","metadata":{}},{"cell_type":"code","source":"class MainModel(nn.Module):\n    def __init__(self, nrace=3, nskin=4):\n        super().__init__()\n        self.backbone = torch.load('/kaggle/working/backbone.pt')\n        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n                                  nn.Flatten())\n        self.fc = nn.Sequential(\n                                nn.Linear(in_features=25088, out_features=4096, bias=True),\n                                nn.ReLU(inplace=True),\n                                nn.Dropout())\n        self.fc.load_state_dict(torch.load('/kaggle/working/fc.pth'))\n        self.racecls = nn.Linear(in_features=4096, out_features=nrace, bias=False)\n        self.racecls.load_state_dict(torch.load('/kaggle/working/race.pth'))\n        self.skincls = nn.Linear(in_features=4096, out_features=nskin, bias=False) \n        self.skincls.load_state_dict(torch.load('/kaggle/working/skin.pth'))\n        self.mask = torch.load('/kaggle/working/masked.pt')\n        self.gender = torch.load('/kaggle/input/gender-pt/gender.pt')\n        self.age = nn.Linear(in_features=4096, out_features=6, bias=False)\n        self.age.load_state_dict(torch.load('/kaggle/working/age.pth'))\n    \n    def forward(self, x):\n        out = self.pool(self.backbone(x))\n        return self.mask(out), self.gender(out), self.racecls(self.fc(out)), \\\n                self.skincls(self.fc(out)), self.age(self.fc(out))\n\nmain_model = MainModel().to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchinfo\ntorchinfo.summary(main_model, input_size=(1,3,image_size,image_size),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = main_model(face1.unsqueeze(0).to(device))\ndef printlabel(out):\n    mask = 'Unmasked' if torch.sigmoid(out[0]) < 0.5 else 'Masked'\n    gender = 'Female' if torch.sigmoid(out[1]) < 0.5 else 'Male'\n    race = torch.argmax(out[2])\n    skin = torch.argmax(out[3])\n    age = torch.argmax(out[4])\n    return mask, gender, race, skin, age\nprint(printlabel(out))\nplt.imshow(face1.permute(1,2,0).numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## dataloader\ndef get_dataloaders(ds, lengths=[0.9, 0.1], batch_size=32, seed=42):\n    train_set, val_set = random_split(ds, lengths=lengths, generator=torch.Generator().manual_seed(seed))\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n    return train_loader, val_loader\n\ntrain_loader, val_loader = get_dataloaders(age_data)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:54:43.563368Z","iopub.execute_input":"2024-01-20T03:54:43.563775Z","iopub.status.idle":"2024-01-20T03:54:43.571552Z","shell.execute_reply.started":"2024-01-20T03:54:43.563742Z","shell.execute_reply":"2024-01-20T03:54:43.570339Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"torch.sum(torch.argmax(y_hat1, dim=1) == y1).item()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_step(batch, model, loss_func, device):\n    x, y = batch\n    x, y = x.to(device), y.to(device)\n    y_hat = model(x).squeeze()\n    loss = loss_func(y_hat, y)\n    return loss, y_hat, y\n\ndef optimizer_step(optimizer, scaler, loss):\n    optimizer.zero_grad()\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n\ndef evaluation(model, loader, loss_func, scheduler, epoch, device, stage='Val'):\n    model.eval()\n    total, total_loss, total_acc = 0, 0, 0\n    pbar = tqdm(loader)\n    with torch.no_grad():\n        for batch in pbar:\n            loss, y_hat, y = model_step(batch, model, loss_func, device)\n            total += len(y)\n            total_loss += loss.item()\n            total_acc += torch.sum(torch.argmax(y_hat, dim=1) == y).item()\n            pbar.set_description(f\"Epoch {epoch} {stage} | Loss = {total_loss/total:.4f} | Acc = {total_acc*100/total:.2f}\")\n        scheduler.step(total_loss/total)\n    return total_loss/total\n\ndef train_epoch(model, train_loader, loss_func, optimizer, scaler, epoch, device):\n    model.train()\n    pbar = tqdm(train_loader)\n    total, total_loss, total_acc = 0, 0, 0\n    for batch in pbar:\n        loss, y_hat, y = model_step(batch, model, loss_func, device)\n        optimizer_step(optimizer, scaler, loss)\n        total += len(y)\n        total_loss += loss.item()\n        total_acc += torch.sum(torch.argmax(y_hat, dim=1) == y).item()\n        pbar.set_description(f\"Epoch {epoch} Train | Loss = {total_loss/total:.4f} | Acc = {total_acc*100/total:.2f}\")\n    return total_loss/total\n\ndef train(model, train_loader, val_loader, loss_func, optimizer, scaler,\n          scheduler, max_epochs=10, device=device, early_stop=False):\n    for epoch in range(max_epochs):\n        ## train loop\n        train_epoch(model, train_loader, loss_func, optimizer, scaler, epoch, device)\n        ## val loop\n        val_loss = evaluation(model, val_loader, loss_func, scheduler, epoch, device)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:54:45.712821Z","iopub.execute_input":"2024-01-20T03:54:45.713855Z","iopub.status.idle":"2024-01-20T03:54:45.728821Z","shell.execute_reply.started":"2024-01-20T03:54:45.713814Z","shell.execute_reply":"2024-01-20T03:54:45.727717Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=amodel.parameters(), lr=1e-3)\nscaler = torch.cuda.amp.GradScaler()\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:54:49.142978Z","iopub.execute_input":"2024-01-20T03:54:49.143643Z","iopub.status.idle":"2024-01-20T03:54:49.150139Z","shell.execute_reply.started":"2024-01-20T03:54:49.143607Z","shell.execute_reply":"2024-01-20T03:54:49.149065Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train(amodel, train_loader, val_loader, loss_fn, optimizer, scaler,\n      scheduler, max_epochs=5, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:54:50.880605Z","iopub.execute_input":"2024-01-20T03:54:50.880989Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 0 Train | Loss = 0.0451 | Acc = 46.40: 100%|██████████| 322/322 [07:47<00:00,  1.45s/it]\nEpoch 0 Val | Loss = 0.0367 | Acc = 54.16: 100%|██████████| 36/36 [00:51<00:00,  1.42s/it]\nEpoch 1 Train | Loss = 0.0409 | Acc = 49.52: 100%|██████████| 322/322 [07:42<00:00,  1.44s/it]\nEpoch 1 Val | Loss = 0.0360 | Acc = 55.29: 100%|██████████| 36/36 [00:51<00:00,  1.44s/it]\nEpoch 2 Train | Loss = 0.0388 | Acc = 52.63:  29%|██▉       | 94/322 [02:15<05:28,  1.44s/it]","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(agemodel.agecls.state_dict(), '/kaggle/working/age.pth')\nprint('Save success')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def masked_inference(\n    model: torch.nn.Module,\n    image_path: str,\n    box, \n    image_size = (224, 224),\n    transform: torchvision.transforms = None,\n    device: torch.device = device):\n\n    img = plt.imread(image_path)\n    face = Image.fromarray(get_crop_face(img, box))\n    \n    if transform is not None:\n        image_transform = transform\n    else:\n        image_transform = transforms.Compose([transforms.Resize(image_size),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                                                         std=[0.229, 0.224, 0.225])])\n\n    model.eval()\n    with torch.inference_mode():\n        transformed_image = image_transform(face).unsqueeze(dim=0)\n        logit = model(transformed_image.to(device))\n\n    pred = torch.sigmoid(logit).item()\n    label = 'unmasked' if pred < 0.5 else 'masked'\n    plt.figure()\n    plt.imshow(face)\n    plt.title(\n        f\"Pred: {label}\"\n    )\n    plt.axis(False)\n    plt.show()\n    return label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"import cv2\nimport os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom PIL import Image\n\n!pip install ultralytics\nfrom ultralytics import YOLO","metadata":{"execution":{"iopub.status.idle":"2024-01-20T04:40:01.623746Z","shell.execute_reply.started":"2024-01-20T04:39:49.630946Z","shell.execute_reply":"2024-01-20T04:40:01.622521Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"image_size = 224\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntransform = transforms.Compose([transforms.Resize((image_size, image_size)),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                        std = [0.225, 0.225, 0.225])])\nrace_dict = {0:'Caucasian', 1:'Mongoloid', 2:'Negroid'}\nskin_dict = {0:'dark', 1:'mid-dark', 2:'light', 3:'mid-light'}\nage_dict = {0:'20-30s', 1:'40-50s', 2:'Baby', 3:'Kid', 4:'Senior', 5:'Teenager'}\nemotion_dict = {\n        0: 'Happiness',\n        1: 'Neutral',\n        2: 'Surprise',\n        3: 'Sadness',\n        4: 'Anger',\n        5: 'Disgust',\n        6: 'Fear'\n    }\n\nclass MainModel(nn.Module):\n    def __init__(self, nrace=3, nskin=4):\n        super().__init__()\n        \n        self.backbone = torch.load('./backbone.pt')\n        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(7, 7)),\n                                  nn.Flatten())\n        self.fc = nn.Sequential(\n                                nn.Linear(in_features=25088, out_features=4096, bias=True),\n                                nn.ReLU(inplace=True),\n                                nn.Dropout())\n        self.fc.load_state_dict(torch.load('./fc.pth'))\n        self.race = nn.Linear(in_features=4096, out_features=nrace, bias=False)\n        self.race.load_state_dict(torch.load('./race.pth'))\n        self.skin = nn.Linear(in_features=4096, out_features=nskin, bias=False) \n        self.skin.load_state_dict(torch.load('./skin.pth'))\n        self.mask = torch.load('./masked.pt')\n        self.gender = torch.load('/kaggle/input/gender-pt/gender.pt')\n        self.age = nn.Linear(in_features=4096, out_features=6, bias=False)\n        self.age.load_state_dict(torch.load('./age.pth'))\n        self.emotion = nn.Linear(in_features=4096, out_features=7, bias=False)\n        self.emotion.load_state_dict(torch.load('/kaggle/input/emotion/emotion.pth'))\n    \n    def forward(self, x):\n        out = self.pool(self.backbone(x))\n        return self.race(self.fc(out)), self.age(self.fc(out)), self.emotion(self.fc(out)), self.gender(out),  \\\n                self.skin(self.fc(out)), self.mask(out)\n\ndef predict(model, yolo, image_path):\n    res = yolo(image_path)\n    box = res[0].boxes[0].xyxy.cpu().numpy()[0]\n    img = cv2.imread(image_path)\n    x1,y1,x2,y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n    crop_img = img[y1:y2, x1:x2, :]\n    input = transform(Image.fromarray(crop_img))\n    out = model(input.unsqueeze(0).to(device))\n    race = race_dict[torch.argmax(out[0]).item()]\n    age = age_dict[torch.argmax(out[1]).item()]\n    emotion = emotion_dict[torch.argmax(out[2]).item()] \n    gender = 'Female' if torch.sigmoid(out[3]) < 0.5 else 'Male'\n    skintone = skin_dict[torch.argmax(out[4]).item()]\n    masked = 'Unmasked' if torch.sigmoid(out[5]) < 0.5 else 'Masked'\n    return box, race, age, emotion, gender, skintone, masked\n    \nmodel = MainModel().to(device)\nyolo = YOLO('/kaggle/input/yolov8/best.pt').to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T04:58:06.984831Z","iopub.execute_input":"2024-01-20T04:58:06.985174Z","iopub.status.idle":"2024-01-20T04:58:09.245422Z","shell.execute_reply.started":"2024-01-20T04:58:06.985148Z","shell.execute_reply":"2024-01-20T04:58:09.244359Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import json\nid_dict = pd.read_json('/kaggle/input/image-id/file_name_to_image_id.json', lines=True)\nid_dict.loc[0]['100429351.jpg']","metadata":{"execution":{"iopub.status.busy":"2024-01-20T04:48:51.538110Z","iopub.execute_input":"2024-01-20T04:48:51.538475Z","iopub.status.idle":"2024-01-20T04:48:52.395764Z","shell.execute_reply.started":"2024-01-20T04:48:51.538447Z","shell.execute_reply":"2024-01-20T04:48:52.394844Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"test_dir = '/kaggle/input/test-data/public_test'\ntest_paths = os.listdir(test_dir)\nfile_name, bbox, image_id, races, ages, emotions, genders, skintones, maskeds =[],[],[],[],[],[],[],[],[]\nfor path in test_paths:\n    file_name.append(path)\n    image_id.append(id_dict.loc[0][path])\n    img_path = test_dir + '/' + path\n    box, race, age, emotion, gender, skintone, masked = predict(model, yolo, img_path)\n    bbox.append(box)\n    races.append(race)\n    ages.append(age)\n    emotions.append(emotion)\n    genders.append(gender)\n    skintones.append(skintone)\n    maskeds.append(masked)\nanswer_df = pd.DataFrame({'file_name':file_name, \n                          'bbox':bbox, \n                          'image_id':image_id, \n                          'race':races, \n                          'age':ages, \n                          'emotion':emotions, \n                          'gender':genders, \n                          'skintone':skintones, \n                          'masked':maskeds})\nanswer_csv = answer_df.to_csv('./answer.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}